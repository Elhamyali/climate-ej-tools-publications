---
title: How climate and envrionmental justice tools are used in research studies
author:
  - name: Elham Ali
    corresponding: true
    roles:
      - Researcher
      - Data Storytelling
      - Human-centered Design
      - Data Visualization
    affiliations:
      - Public Environmental Data Project
license: CC BY-SA 4.0
keywords:
  - climate change
  - environmental justice
  - digital tools
  - research studies
  - academic research
date: last-modified
abstract: |
  TBD
keypoints:
  - climate change
  - environmental justice
  - digital tools
  - research studies
  - academic research
citation:
  container-title: Public Environmental Data Project
draft: false
bibliography: references.bib
code-fold: false
# reference-location: margin
# citation-location: margin
echo: true
warning: false
---

## Background

When public climate & EJ evidence disappears (removed, restricted, or altered), a decade of downstream knowledge becomes harder to verify, reproduce, teach, or apply—especially for communities and decisions that most need it.\
This analysis looks at how many studies have used these tools, their topics, and their use cases.

## Questions

Here are the key questions explored in this analysis:

-   How many research papers or studies have cited or relied on five U.S. federal climate and environmental tools that are threatened, not being maintained, or no longer available?\
-   What research topics are associated with each tool, and how do these topics vary by citation frequency?\
-   In what ways are these tools applied in research?

## Data Sources

The climate tools assessed are:

-   CEQ’s **Climate and Economic Justice Screening Tool (CEJST)**\
-   EPA’s **EJScreen**\
-   USDA Forest Service’s **Climate Risk Viewer (CRV)**\
-   FEMA’s **Future Risk Index (FRI)**\
-   CDC’s **Environmental Justice Index (EJI)**

The data for this project comes from Google scholar and last refreshed on August 29, 2025.

Original raw datasets are saved in the `data/` folder. This script reduces and cleans those datasets to prepare them for analysis.

------------------------------------------------------------------------

## Cleaning

I start by loading the packages needed for file handling, data wrangling, and visualization.

```{r load-libraries, echo = TRUE, message = FALSE, results = 'markup'}
#| label: load-libraries

## Folder structure helpers
library(here)
library(ezknitr)

## Data import & cleaning
library(tidyverse)  # includes dplyr, purrr, readr, tidyr, stringr, etc.
library(janitor)
library(lubridate)
library(janitor)
# library(rlang)

## Visualization
library(highcharter)
library(igraph)
library(RColorBrewer)
library(htmlwidgets)
library(gt)
```

### Import raw data

I import all .csv files from the `data/` folder, then save them as .rds files into `output/`. This preserves their structure and speeds up future reads.

```{r import-data, echo = TRUE, message = FALSE, results = 'markup'}
#| label: import-data

# List all CSV files
csv_files <- list.files(here("data"), pattern = "\\.csv$", full.names = TRUE)

# Read into a list of dataframes
datasets <- map(csv_files, read.csv)
names(datasets) <- tools::file_path_sans_ext(basename(csv_files))

# Save each dataset as .rds in output/
walk2(
  datasets,
  names(datasets),
  ~ saveRDS(.x, here("output", paste0(.y, ".rds")))
)
```

### Merge EJScreen datasets

Google Scholar caps search results at 1,000 records [@harzing2025].

Because EJScreen returned more than this, I split the results into four files (ejscreen_1–ejscreen_4). Here I combine them into one dataframe.

```{r ejscreen-cleaning, echo = TRUE, message = FALSE, results = 'markup'}
#| label: ejscreen-cleaning

# List EJScreen RDS files
ejscreen_files <- here("output") |>
  list.files(pattern = "^ejscreen_\\d+\\.rds$", full.names = TRUE)

# Read, tag, clean variable names
ejscreen_list <- map(ejscreen_files, ~ {
  readRDS(.x) |>
    mutate(source_file = tools::file_path_sans_ext(basename(.x))) |>
    janitor::clean_names()
})

# Merge into one dataframe
ejscreen_all <- bind_rows(ejscreen_list)

# Quick check on dimensions
dim(ejscreen_all)  

```

### Clean and tag all other tools

I apply the same cleaning process to the other tools (CEJST, CRV, EJI, FRI):

-   Standardize variable names to snake_case
-   Add a source_file column for provenance
-   Guess variable types (integers, doubles, dates, etc.)

```{r remaining-tools-cleaning, echo = TRUE, message = FALSE, results = 'markup'}
#| label: remaining-tools-cleaning

# Helper function: read, clean names, add provenance, type-convert
read_clean_tag <- function(path) {
  df <- readRDS(path) |>
    janitor::clean_names()

  source_stem <- tools::file_path_sans_ext(basename(path))  # e.g., "ejscreen_1" or "cejst"

  df |>
    mutate(
      source_file = source_stem,
      tool_name   = sub("_\\d+$", "", source_stem)  # "ejscreen_1" -> "ejscreen"; "cejst" -> "cejst"
    ) |>
    readr::type_convert(col_types = readr::cols(.default = readr::col_guess())) |>
    mutate(across(where(is.character), trimws))
}
# 
# # Rebuild ejscreen_all if needed
# if (!exists("ejscreen_all")) {
#   ejs_files <- list.files(here("output"), pattern = "^ejscreen_\\d+\\.rds$", full.names = TRUE)
#   ejscreen_all <- ejs_files |> map(read_clean_tag) |> list_rbind()
# }

# Process other tools
other_tools <- c("cejst", "crv", "eji", "fri")
other_paths <- here("output", paste0(other_tools, ".rds"))

other_list <- other_paths |>
  set_names(~ tools::file_path_sans_ext(basename(.x))) |>
  map(read_clean_tag)

```

### Final merge and labeling

I now merge all tools into a single dataset. Additional steps:

-   Ensure consistent date formats
-   Map tool codes (ejscreen, cejst, etc.) to their full names
-   Drop empty placeholder columns

```{r final-cleaning, echo = TRUE, message = FALSE, results = 'markup'}
#| label: final-cleaning

# Helper: coerce anything date-like into Date
to_Date <- function(x) {
  if (inherits(x, "Date"))    return(x)
  if (inherits(x, "POSIXt"))  return(as_date(x))
  if (is.numeric(x))          return(as_date(as.POSIXct(x, origin = "1970-01-01", tz = "UTC")))
  if (is.character(x)) {
    suppressWarnings({
      dt <- ymd_hms(x, quiet = TRUE, tz = "UTC")
      idx <- is.na(dt); if (any(idx)) dt[idx] <- ymd(x[idx], quiet = TRUE)
      idx <- is.na(dt); if (any(idx)) dt[idx] <- mdy(x[idx], quiet = TRUE)
      idx <- is.na(dt); if (any(idx)) dt[idx] <- dmy(x[idx], quiet = TRUE)
    })
    return(as_date(dt))
  }
  as_date(as.character(x))
}

# Apply date coercion
if ("query_date" %in% names(ejscreen_all)) {
  ejscreen_all <- ejscreen_all %>% mutate(query_date = to_Date(query_date))
}

if (exists("ejscreen_all") && "query_date" %in% names(ejscreen_all)) {
  ejscreen_all <- ejscreen_all %>% mutate(query_date = to_Date(query_date))
}

if (exists("other_list")) {
  other_list <- other_list %>%
    map(~ if ("query_date" %in% names(.x)) mutate(.x, query_date = to_Date(query_date)) else .x)
} else {
  other_list <- list()
}

# Merge all datasets
all_tools <- bind_rows(ejscreen_all, !!!other_list)

# Map tool codes to full names
all_tools <- all_tools %>%
  mutate(
    source_file = if_else(is.na(source_file) | source_file == "",
                          coalesce(source_file, tool_name), source_file),
    base_tool   = sub("_\\d+$", "", source_file),   # ejscreen_1 -> ejscreen
    tool_name   = dplyr::recode(
      base_tool,
      ejscreen = "EJScreen",
      cejst    = "Climate and Economic Justice Screening Tool (CEJST)",
      crv      = "Climate Risk Viewer",
      fri      = "Future Risk Index (FRI)",
      eji      = "Environmental Justice Index (EJI)",
      .default = tool_name  # keep whatever was there if not matched
    )
  ) %>%
  select(-base_tool)

# Drop empty placeholder columns
all_tools <- all_tools %>%
  select(-any_of(c("issn", "citation_url", "volume", "issue", "start_page", "end_page")))

# Save combined dataset
glimpse(all_tools)
saveRDS(all_tools, here("output", "all_tools.rds"))
write_csv(all_tools, here("output", "all_tools.csv"))

```

## Analysis

I will look at each question one by one and clean the data as I go. I will organize the data during the analysis before exploring the results. I'll also export intermediate results into tidy CSV files so they are ready for further visualization and exploration.

### Research question 1

How many research papers or studies have cited or relied on five U.S. federal climate and environmental tools that are threatened, not being maintained, or no longer available?

#### Total number of studies

```{r descriptive-stat-1, echo = TRUE, message = FALSE, results = 'markup'}
#| label: descriptive-stat-1

nrow (all_tools)

write_csv(tibble(total_studies = nrow(all_tools)), here("viz", "total_studies.csv"))
```

#### Count of studies per tool

```{r descriptive-stat-2, echo = TRUE, message = FALSE, results = 'markup'}
#| label: descriptive-stat-2

df_tool <- all_tools %>%
  count(tool_name, name = "n_studies") %>%
  arrange(desc(n_studies))

hchart(df_tool, "column", hcaes(x = tool_name, y = n_studies)) %>%
  hc_title(text = "Number of studies by tool") %>%
  hc_subtitle(text = "Total count of research papers citing or relying on each tool") %>%
  hc_xAxis(title = list(text = "Tool")) %>%
  hc_yAxis(title = list(text = "Number of studies"), allowDecimals = FALSE) %>%
  hc_tooltip(pointFormat = "<b>{point.y}</b> studies") %>%
  hc_legend(enabled = FALSE) %>%
  hc_exporting(enabled = TRUE)

write_csv(df_tool, here("viz", "count_per_tool.csv"))
```

#### Count of studies per year per tool

```{r descriptive-stat-3, echo = TRUE, message = FALSE, results = 'markup'}
#| label: descriptive-stat-3

df_year_tool <- all_tools %>%
  filter(!is.na(year)) %>%
  count(tool_name, year, name = "n_studies") %>%
  arrange(tool_name, year)

hchart(
  df_year_tool,
  "line",
  hcaes(x = year, y = n_studies, group = tool_name)
) %>%
  hc_title(text = "Studies over time by tool") %>%
  hc_subtitle(text = "Annual counts of studies citing or relying on each tool") %>%
  hc_xAxis(title = list(text = "Year"), allowDecimals = FALSE) %>%
  hc_yAxis(title = list(text = "Number of studies"), allowDecimals = FALSE) %>%
  hc_tooltip(shared = TRUE, crosshairs = TRUE,
             headerFormat = "<b>Year: {point.key}</b><br/>",
             pointFormat = "{series.name}: <b>{point.y}</b><br/>") %>%
  hc_legend(title = list(text = "Tool")) %>%
  hc_exporting(enabled = TRUE)

write_csv(df_year_tool, here("viz", "count_per_year_per_tool.csv"))
```

#### Top 10 most cited studies overall per tool

```{r descriptive-stat-4, echo = TRUE, message = FALSE, results = 'markup'}
#| label: descriptive-stat-4

df_top_cites <- all_tools %>%
  filter(!is.na(cites)) %>%
  group_by(tool_name) %>%
  slice_max(order_by = cites, n = 10, with_ties = FALSE) %>%
  ungroup() %>%
  select(tool_name, year, title, cites, authors) %>%
  arrange(tool_name, desc(cites))

# Show table (optional)
df_top_cites

# Ensure viz/ exists, then export
if (!dir.exists(here::here("viz"))) dir.create(here::here("viz"), recursive = TRUE)
readr::write_csv(df_top_cites, here::here("viz", "top10_cites_per_tool.csv"))
```

#### Top 10 highest `cites_per_year` per tool

This shows which studies are “most cited relative to their age.”

```{r descriptive-stat-5, echo = TRUE, message = FALSE, results = 'markup'}
#| label: descriptive-stat-5

df_top_cpy <- all_tools %>%
  filter(!is.na(cites_per_year)) %>%
  group_by(tool_name) %>%
  slice_max(order_by = cites_per_year, n = 10, with_ties = FALSE) %>%
  ungroup()

df_top_cpy %>% 
  select(tool_name, year, title, cites_per_year, cites, authors) %>%
  arrange(tool_name, desc(cites_per_year))

hchart(
  df_top_cpy,
  "bar",
  hcaes(x = reorder(title, cites_per_year), y = cites_per_year, group = tool_name)
) %>%
  hc_title(text = "Top 10 studies by cites per year, per tool") %>%
  hc_subtitle(text = "Highlights studies with the highest relative citation rates") %>%
  hc_xAxis(title = list(text = "Study title"), labels = list(enabled = FALSE)) %>%  # hide long labels
  hc_yAxis(title = list(text = "Cites per year")) %>%
  hc_tooltip(pointFormat = "<b>{point.y}</b> cites/year<br>{point.tool_name}<br>") %>%
  hc_exporting(enabled = TRUE)

write_csv(df_top_cpy, here("viz", "top10_cites_per_year_per_tool.csv"))
```

#### Average `cites_per_year` over time per tool

This shows whether more recent papers citing a tool are getting traction.

```{r descriptive-stat-6, echo = TRUE, message = FALSE, results = 'markup'}
#| label: descriptive-stat-6

df_avg_cpy <- all_tools %>%
  filter(!is.na(year), !is.na(cites_per_year)) %>%
  group_by(tool_name, year) %>%
  summarise(avg_cpy = mean(cites_per_year, na.rm = TRUE), .groups = "drop")

hchart(df_avg_cpy, "line", hcaes(x = year, y = avg_cpy, group = tool_name)) %>%
  hc_title(text = "Average cites per year over time, by tool") %>%
  hc_yAxis(title = list(text = "Average cites per year")) %>%
  hc_exporting(enabled = TRUE)

write_csv(df_avg_cpy, here("viz", "avg_cites_per_year_over_time.csv"))
```

#### Publishers

Which publishers/platforms appear most frequently?

```{r descriptive-stat-7, echo = TRUE, message = FALSE, results = 'markup'}
#| label: descriptive-stat-7

df_publishers <- all_tools %>%
  filter(publisher != "") %>%
  count(publisher, sort = TRUE) %>%
  slice_head(n = 10)

df_publishers

write_csv(df_publishers, here("viz", "top_publishers.csv"))
```

### Research question 2

What research topics are associated with each tool, and how do these topics vary by citation frequency?

To answer this question, I will work with a collaborator to "code" all of the research studies manually and to categorize them into topics. Before we do that, I'


### Research question 3

In what ways are these tools applied in research?
